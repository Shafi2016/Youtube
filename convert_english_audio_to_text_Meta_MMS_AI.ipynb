{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install pytube for YouTube video downloading\n",
        "!pip install pytube\n",
        "# Install pydub for audio manipulation\n",
        "!pip install pydub\n"
      ],
      "metadata": {
        "id": "WPu2VdbAQODq",
        "outputId": "0fef6b36-c182-4867-fa20-5e4d49fd9d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from pytube import YouTube\n",
        "\n",
        "#class from the pydub package is imported to manipulate audio files, such as slicing and exporting.\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# URL of the video\n",
        "url = 'https://www.youtube.com/watch?v=T1WAHb47ChI&t=60s'\n",
        "\n",
        "youtube = YouTube(url)\n",
        "\n",
        "#The audio stream of the YouTube video is filtered and the first available audio stream is selected.\n",
        "video = youtube.streams.filter(only_audio=True).first()\n",
        "out_file = video.download(output_path=\"/content/\")\n",
        "\n",
        "# Load and slice the audio\n",
        "audio = AudioSegment.from_file(out_file, format=\"mp4\")\n",
        "sliced_audio = audio[:1*60*1000]  # Slicing first 1 mins, pydub works in milliseconds\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/content/chunk2', exist_ok=True)\n",
        "\n",
        "# Export the audio to the directory\n",
        "sliced_audio.export(\"/content/chunk2/audio.wav\", format=\"wav\")\n"
      ],
      "metadata": {
        "id": "gf7_1_5ink31",
        "outputId": "98c933c3-9877-4204-a14e-3af9bcd6a0bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/chunk2/audio.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "input_filename = \"/content/chunk2/audio.wav\"\n",
        "output_filename = \"/content/chunk2/urdu_10_16k.wav\"  # Updated filename\n",
        "\n",
        "#The command list is created, which represents the command to be executed using FFmpeg. \n",
        "# It specifies the input file, the desired audio sample rate of 16000 Hz, and the output file.\n",
        "\n",
        "command = ['ffmpeg', '-y', '-i', input_filename, '-ar', '16000', output_filename]\n",
        "\n",
        "#The subprocess.run() function is called to execute the FFmpeg command. \n",
        "#This command will resample the input audio file to a sample rate of 16000 Hz and save it as the output file.\n",
        "\n",
        "subprocess.run(command)\n"
      ],
      "metadata": {
        "id": "200cy_Brscd1",
        "outputId": "71a04d48-c04c-496d-e8b4-56e18ba1ca25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['ffmpeg', '-y', '-i', '/content/chunk2/audio.wav', '-ar', '16000', '/content/chunk2/urdu_10_16k.wav'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"temp_dir\"\n",
        "\n",
        "#git clone command. \n",
        "#It fetches the source code and creates a local copy of the repository on your machine.\n",
        "\n",
        "!git clone https://github.com/pytorch/fairseq\n",
        "\n",
        "# Change current working directory\n",
        "#The !pwd command prints the current working directory, displaying the current path. \n",
        "!pwd\n",
        "\n",
        "#The %cd command changes the current working directory to \"/content/fairseq\".\n",
        "\n",
        "%cd \"/content/fairseq\"\n",
        "\n",
        "#The --editable flag indicates that the package should be installed in editable mode, \n",
        "#allowing modifications to the package source code without needing to reinstall it.\n",
        "#./ refers to the current directory\n",
        "!pip install --editable ./ \n",
        "\n",
        "#tensorboardX is a library that provides a wrapper around TensorFlow's \n",
        "#TensorBoard, enabling visualization and logging of training progress and results.\n",
        "\n",
        "!pip install tensorboardX\n"
      ],
      "metadata": {
        "id": "WAIW6wf-oKbt",
        "outputId": "cecc2b75-97da-439e-d52d-b338f4b03796",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34724, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 34724 (delta 92), reused 141 (delta 68), pack-reused 34543\u001b[K\n",
            "Receiving objects: 100% (34724/34724), 25.00 MiB | 27.83 MiB/s, done.\n",
            "Resolving deltas: 100% (25193/25193), done.\n",
            "/content\n",
            "/content/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fairseq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use colab free\n",
        "# MMS-1B:FL102 model - 102 Languages - FLEURS Dataset\n",
        "#!wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_fl102.pt'\n"
      ],
      "metadata": {
        "id": "i0jrZ-gIsVTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use high RAM, such as colab pro\n",
        "# # MMS-1B-all - 1162 Languages - MMS-lab + FLEURS + CV + VP + MLS\n",
        "!wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_all.pt'"
      ],
      "metadata": {
        "id": "VoecrJRInviT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "\n",
        "# Set the value of the environment variable \"TMPDIR\"\n",
        "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
        "\n",
        "# Set the value of the environment variable \"PYTHONPATH\"\n",
        "os.environ[\"PYTHONPATH\"] = \".\"\n",
        "\n",
        "# Set the value of the environment variable \"PREFIX\"\n",
        "os.environ[\"PREFIX\"] = \"INFER\"\n",
        "\n",
        "# Set the value of the environment variable \"HYDRA_FULL_ERROR\"\n",
        "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
        "\n",
        "# Set the value of the environment variable \"USER\"\n",
        "os.environ[\"USER\"] = \"micro\"\n",
        "\n",
        "filename = \"/content/chunk2/urdu_10_16k.wav\"\n",
        "\n",
        "# Open a file named \"output.txt\" in write mode\n",
        "with open('/content/chunk2/output.txt', 'w') as f:\n",
        "\n",
        "    # Command to run MMS inference\n",
        "    command = ['python', 'examples/mms/asr/infer/mms_infer.py', '--model', '/content/fairseq/models_new/mms1b_all.pt', '--lang', 'eng', '--audio', filename]\n",
        "\n",
        "    # Run the command and redirect the standard output to the file\n",
        "    subprocess.run(command, stdout=f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FdyCmaVNtuFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "from pydub import AudioSegment\n",
        "import subprocess\n",
        "\n",
        "# URL of the video\n",
        "url = 'https://www.youtube.com/watch?v=T1WAHb47ChI&t=60s'\n",
        "\n",
        "youtube = YouTube(url)\n",
        "video = youtube.streams.filter(only_audio=True).first()\n",
        "out_file = video.download(output_path=\"/content/\")\n",
        "\n",
        "# Load the audio\n",
        "audio = AudioSegment.from_file(out_file, format=\"mp4\")\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/content/chunk4', exist_ok=True)\n",
        "\n",
        "# Determine the end time for slicing in milliseconds\n",
        "end_time = 10*60*1000  # 10 minutes\n",
        "\n",
        "# Initialize start time and chunk size in milliseconds\n",
        "start_time = 0\n",
        "chunk_size = 60*1000  # 60 seconds\n",
        "\n",
        "# Slice and export each 60-second chunk of audio\n",
        "i = 0\n",
        "while start_time < end_time:\n",
        "    # Calculate the end time for the current slice\n",
        "    slice_end_time = min(start_time + chunk_size, end_time)\n",
        "    \n",
        "    # Slice the audio\n",
        "    sliced_audio = audio[start_time:slice_end_time]\n",
        "    \n",
        "    # Export the sliced audio\n",
        "    original_filename = f\"/content/chunk4/audio_{i}.wav\"\n",
        "    sliced_audio.export(original_filename, format=\"wav\")\n",
        "    \n",
        "    # Apply the ffmpeg process\n",
        "    output_filename = f\"/content/chunk4/urdu_{i}_16k.wav\"  # Updated filename\n",
        "    command = ['ffmpeg', '-y', '-i', original_filename, '-ar', '16000', output_filename]\n",
        "    subprocess.run(command)\n",
        "    \n",
        "    # Move to the next slice\n",
        "    start_time += chunk_size\n",
        "    i += 1\n"
      ],
      "metadata": {
        "id": "LKWj0uyU7f7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
        "os.environ[\"PYTHONPATH\"] = \".\"\n",
        "os.environ[\"PREFIX\"] = \"INFER\"\n",
        "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
        "os.environ[\"USER\"] = \"micro\"\n",
        "\n",
        "# Define your directory\n",
        "directory = '/content/chunk4/'\n",
        "\n",
        "# Define the range of file indices\n",
        "file_indices = range(10)  # This will give you the numbers 0 to 9\n",
        "\n",
        "# Define a single output file to store all transcriptions\n",
        "combined_output_filename = os.path.join(directory, 'combined_transcription.txt')\n",
        "\n",
        "# Check if combined transcription file already exists and if so, remove it\n",
        "if os.path.exists(combined_output_filename):\n",
        "    os.remove(combined_output_filename)\n",
        "\n",
        "# Loop through the file indices\n",
        "for i in file_indices:\n",
        "    # Construct the input file name\n",
        "    input_filename = os.path.join(directory, f'urdu_{i}_16k.wav')\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(input_filename):\n",
        "        print(f\"File {input_filename} does not exist, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Define the output filename for the transcription\n",
        "    output_filename = os.path.join(directory, f'transcription_{i}.txt')\n",
        "\n",
        "    # Open the transcription file in write mode\n",
        "    with open(output_filename, 'w') as f:\n",
        "        # Run the model inference on the audio file and save the output to the file\n",
        "        subprocess.run(['python', 'examples/mms/asr/infer/mms_infer.py', '--model', '/content/fairseq/models_new/mms1b_all.pt', '--lang', 'eng', '--audio', input_filename], stdout=f)\n",
        "\n",
        "    # Now, append the individual transcription to the combined file\n",
        "    with open(output_filename, 'r') as f_in, open(combined_output_filename, 'a') as f_out:\n",
        "        # Read the individual transcription and write it to the combined file\n",
        "        f_out.write(f_in.read())\n",
        "        # Optionally, write a newline character to separate the transcriptions\n",
        "        f_out.write('\\n')\n"
      ],
      "metadata": {
        "id": "8_H1uh3MULP3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}