{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install pytube for YouTube video downloading\n",
        "!pip install pytube\n",
        "# Install pydub for audio manipulation\n",
        "!pip install pydub\n"
      ],
      "metadata": {
        "id": "WPu2VdbAQODq",
        "outputId": "c97fb599-6d73-4da0-8cf0-05d7b774a1e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from pytube import YouTube\n",
        "\n",
        "#class from the pydub package is imported to manipulate audio files, such as slicing and exporting.\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# URL of the video\n",
        "url = 'https://www.youtube.com/watch?v=_NdA1kNxuJ4&t=1s'\n",
        "\n",
        "youtube = YouTube(url)\n",
        "\n",
        "#The audio stream of the YouTube video is filtered and the first available audio stream is selected.\n",
        "video = youtube.streams.filter(only_audio=True).first()\n",
        "out_file = video.download(output_path=\"/content/\")\n",
        "\n",
        "# Load and slice the audio\n",
        "audio = AudioSegment.from_file(out_file, format=\"mp4\")\n",
        "sliced_audio = audio[:1*60*1000]  # Slicing first 1 mins, pydub works in milliseconds\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/content/chunk2', exist_ok=True)\n",
        "\n",
        "# Export the audio to the directory\n",
        "sliced_audio.export(\"/content/chunk2/audio.wav\", format=\"wav\")\n"
      ],
      "metadata": {
        "id": "gf7_1_5ink31",
        "outputId": "d13d1604-8416-41e1-e741-34362f7e6fcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/chunk2/audio.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "input_filename = \"/content/chunk2/audio.wav\"\n",
        "output_filename = \"/content/chunk2/urdu_10_16k.wav\"  # Updated filename\n",
        "\n",
        "#The command list is created, which represents the command to be executed using FFmpeg. \n",
        "# It specifies the input file, the desired audio sample rate of 16000 Hz, and the output file.\n",
        "\n",
        "command = ['ffmpeg', '-y', '-i', input_filename, '-ar', '16000', output_filename]\n",
        "\n",
        "#The subprocess.run() function is called to execute the FFmpeg command. \n",
        "#This command will resample the input audio file to a sample rate of 16000 Hz and save it as the output file.\n",
        "\n",
        "subprocess.run(command)\n"
      ],
      "metadata": {
        "id": "200cy_Brscd1",
        "outputId": "5762974e-114e-4913-ae3e-9c9a9cc7908d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['ffmpeg', '-y', '-i', '/content/chunk2/audio.wav', '-ar', '16000', '/content/chunk2/urdu_10_16k.wav'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"temp_dir\"\n",
        "\n",
        "#git clone command. \n",
        "#It fetches the source code and creates a local copy of the repository on your machine.\n",
        "\n",
        "!git clone https://github.com/pytorch/fairseq\n",
        "\n",
        "# Change current working directory\n",
        "#The !pwd command prints the current working directory, displaying the current path. \n",
        "!pwd\n",
        "\n",
        "#The %cd command changes the current working directory to \"/content/fairseq\".\n",
        "\n",
        "%cd \"/content/fairseq\"\n",
        "\n",
        "#The --editable flag indicates that the package should be installed in editable mode, \n",
        "#allowing modifications to the package source code without needing to reinstall it.\n",
        "#./ refers to the current directory\n",
        "!pip install --editable ./ \n",
        "\n",
        "#tensorboardX is a library that provides a wrapper around TensorFlow's \n",
        "#TensorBoard, enabling visualization and logging of training progress and results.\n",
        "\n",
        "!pip install tensorboardX\n"
      ],
      "metadata": {
        "id": "WAIW6wf-oKbt",
        "outputId": "532f7f06-ec5d-4df7-fb56-56024222f53d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34724, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 34724 (delta 91), reused 142 (delta 68), pack-reused 34543\u001b[K\n",
            "Receiving objects: 100% (34724/34724), 25.01 MiB | 23.15 MiB/s, done.\n",
            "Resolving deltas: 100% (25183/25183), done.\n",
            "/content\n",
            "/content/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.22.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2022.10.31)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.65.0)\n",
            "Collecting bitarray (from fairseq==0.12.2)\n",
            "  Downloading bitarray-2.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.0.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (23.1)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.5.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->fairseq==0.12.2) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->fairseq==0.12.2) (16.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp310-cp310-linux_x86_64.whl size=9219 sha256=5e64e4d35a8b4d649cac841f7cc24e5c52bba5dd5173ac4d12b836c2d5196b19\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1_y5q6wh/wheels/c6/d7/db/bc419b1daa8266aa8de2a7c4d29f62dbfa814e8701fe4695a2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=c551c5033bda3db89659def723bc064211728291a43521acc401d16a98f07464\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.5 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use colab free\n",
        "# MMS-1B:FL102 model - 102 Languages - FLEURS Dataset\n",
        "#!wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_fl102.pt'\n"
      ],
      "metadata": {
        "id": "i0jrZ-gIsVTV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use high RAM, such as colab pro\n",
        "# # MMS-1B-all - 1162 Languages - MMS-lab + FLEURS + CV + VP + MLS\n",
        "!wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_all.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoecrJRInviT",
        "outputId": "65fac96d-9209-4093-90e8-05876a99ee91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-11 01:49:40--  https://dl.fbaipublicfiles.com/mms/asr/mms1b_all.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.219.33, 13.227.219.10, 13.227.219.70, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.219.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14660831159 (14G) [binary/octet-stream]\n",
            "Saving to: ‘./models_new/mms1b_all.pt’\n",
            "\n",
            "mms1b_all.pt        100%[===================>]  13.65G   239MB/s    in 60s     \n",
            "\n",
            "2023-06-11 01:50:39 (234 MB/s) - ‘./models_new/mms1b_all.pt’ saved [14660831159/14660831159]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "\n",
        "# Set the value of the environment variable \"TMPDIR\"\n",
        "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
        "\n",
        "# Set the value of the environment variable \"PYTHONPATH\"\n",
        "os.environ[\"PYTHONPATH\"] = \".\"\n",
        "\n",
        "# Set the value of the environment variable \"PREFIX\"\n",
        "os.environ[\"PREFIX\"] = \"INFER\"\n",
        "\n",
        "# Set the value of the environment variable \"HYDRA_FULL_ERROR\"\n",
        "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
        "\n",
        "# Set the value of the environment variable \"USER\"\n",
        "os.environ[\"USER\"] = \"micro\"\n",
        "\n",
        "filename = \"/content/chunk2/urdu_10_16k.wav\"\n",
        "\n",
        "# Open a file named \"output.txt\" in write mode\n",
        "with open('/content/chunk2/output.txt', 'w') as f:\n",
        "\n",
        "    # Command to run MMS inference\n",
        "    command = ['python', 'examples/mms/asr/infer/mms_infer.py', '--model', '/content/fairseq/models_new/mms1b_all.pt', '--lang', 'urd-script_arabic', '--audio', filename]\n",
        "\n",
        "    # Run the command and redirect the standard output to the file\n",
        "    subprocess.run(command, stdout=f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FdyCmaVNtuFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "from pydub import AudioSegment\n",
        "import subprocess\n",
        "\n",
        "# URL of the video\n",
        "url = 'https://www.youtube.com/watch?v=_NdA1kNxuJ4&t=1s'\n",
        "\n",
        "youtube = YouTube(url)\n",
        "video = youtube.streams.filter(only_audio=True).first()\n",
        "out_file = video.download(output_path=\"/content/\")\n",
        "\n",
        "# Load the audio\n",
        "audio = AudioSegment.from_file(out_file, format=\"mp4\")\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/content/chunk4', exist_ok=True)\n",
        "\n",
        "# Determine the end time for slicing in milliseconds\n",
        "end_time = 10*60*1000  # 10 minutes\n",
        "\n",
        "# Initialize start time and chunk size in milliseconds\n",
        "start_time = 0\n",
        "chunk_size = 60*1000  # 60 seconds\n",
        "\n",
        "# Slice and export each 60-second chunk of audio\n",
        "i = 0\n",
        "while start_time < end_time:\n",
        "    # Calculate the end time for the current slice\n",
        "    slice_end_time = min(start_time + chunk_size, end_time)\n",
        "    \n",
        "    # Slice the audio\n",
        "    sliced_audio = audio[start_time:slice_end_time]\n",
        "    \n",
        "    # Export the sliced audio\n",
        "    original_filename = f\"/content/chunk4/audio_{i}.wav\"\n",
        "    sliced_audio.export(original_filename, format=\"wav\")\n",
        "    \n",
        "    # Apply the ffmpeg process\n",
        "    output_filename = f\"/content/chunk4/urdu_{i}_16k.wav\"  # Updated filename\n",
        "    command = ['ffmpeg', '-y', '-i', original_filename, '-ar', '16000', output_filename]\n",
        "    subprocess.run(command)\n",
        "    \n",
        "    # Move to the next slice\n",
        "    start_time += chunk_size\n",
        "    i += 1\n"
      ],
      "metadata": {
        "id": "LKWj0uyU7f7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
        "os.environ[\"PYTHONPATH\"] = \".\"\n",
        "os.environ[\"PREFIX\"] = \"INFER\"\n",
        "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
        "os.environ[\"USER\"] = \"micro\"\n",
        "\n",
        "# Define your directory\n",
        "directory = '/content/chunk4/'\n",
        "\n",
        "# Define the range of file indices\n",
        "file_indices = range(10)  # This will give you the numbers 0 to 9\n",
        "\n",
        "# Define a single output file to store all transcriptions\n",
        "combined_output_filename = os.path.join(directory, 'combined_transcription.txt')\n",
        "\n",
        "# Check if combined transcription file already exists and if so, remove it\n",
        "if os.path.exists(combined_output_filename):\n",
        "    os.remove(combined_output_filename)\n",
        "\n",
        "# Loop through the file indices\n",
        "for i in file_indices:\n",
        "    # Construct the input file name\n",
        "    input_filename = os.path.join(directory, f'urdu_{i}_16k.wav')\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(input_filename):\n",
        "        print(f\"File {input_filename} does not exist, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Define the output filename for the transcription\n",
        "    output_filename = os.path.join(directory, f'transcription_{i}.txt')\n",
        "\n",
        "    # Open the transcription file in write mode\n",
        "    with open(output_filename, 'w') as f:\n",
        "        # Run the model inference on the audio file and save the output to the file\n",
        "        subprocess.run(['python', 'examples/mms/asr/infer/mms_infer.py', '--model', '/content/fairseq/models_new/mms1b_all.pt', '--lang', 'urd-script_arabic', '--audio', input_filename], stdout=f)\n",
        "\n",
        "    # Now, append the individual transcription to the combined file\n",
        "    with open(output_filename, 'r') as f_in, open(combined_output_filename, 'a') as f_out:\n",
        "        # Read the individual transcription and write it to the combined file\n",
        "        f_out.write(f_in.read())\n",
        "        # Optionally, write a newline character to separate the transcriptions\n",
        "        f_out.write('\\n')\n"
      ],
      "metadata": {
        "id": "8_H1uh3MULP3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}