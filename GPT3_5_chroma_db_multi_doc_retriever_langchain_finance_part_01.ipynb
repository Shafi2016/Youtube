{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#  install several Python packages,\n",
        "!pip -q install langchain openai tiktoken chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhGXr8SDhZ0w",
        "outputId": "6f5b1c96-5b84-4c21-8a4f-86a809ece136"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.1/965.1 kB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.1/414.1 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m464.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n6WCDVXH2N1",
        "outputId": "58e92137-045b-4368-a341-48b3468386f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unzip\n",
            "  Downloading unzip-1.0.0.tar.gz (704 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unzip\n",
            "  Building wheel for unzip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unzip: filename=unzip-1.0.0-py3-none-any.whl size=1279 sha256=4a8a6e46e8b4ba6d6af5cbc9cda9b6d45da09257e8904077f6ede57e493a9b01\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/dc/7a/f8af45bc239e7933509183f038ea8d46f3610aab82b35369f4\n",
            "Successfully built unzip\n",
            "Installing collected packages: unzip\n",
            "Successfully installed unzip-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain multi-doc retriever with ChromaDB"
      ],
      "metadata": {
        "id": "O3YIREjnIiPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up LangChain"
      ],
      "metadata": {
        "id": "LIdtYmCwJDGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your key\""
      ],
      "metadata": {
        "id": "QI2Lu2x-JViE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "bqi6q_gvJFVN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load multiple and process documents"
      ],
      "metadata": {
        "id": "C_jH9LCpJqvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data source, https://themarketswatch.com/financial/top-stocks-to-buy/?gclid=CjwKCAjwyqWkBhBMEiwAp2yUFpSLJZSVwVHJR3co5yVHVLeBPqNNcU3VMrFJjniP3jtuupP6kHzDYxoC8dkQAvD_BwE\n",
        "import zipfile\n",
        "!wget https://github.com/Shafi2016/Youtube/raw/main/stock_market_june_2023.zip -O stock_market_june_2023.zip  # Downloads the zip file from the specified URL.\n",
        "\n",
        "with zipfile.ZipFile('stock_market_june_2023.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t4Pdr2LJsR6",
        "outputId": "c5808d11-fd67-418d-a485-08fe09bd5acc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-17 16:18:58--  https://github.com/Shafi2016/Youtube/raw/main/stock_market_june_2023.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Shafi2016/Youtube/main/stock_market_june_2023.zip [following]\n",
            "--2023-06-17 16:18:59--  https://raw.githubusercontent.com/Shafi2016/Youtube/main/stock_market_june_2023.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10638 (10K) [application/zip]\n",
            "Saving to: ‘stock_market_june_2023.zip’\n",
            "\n",
            "stock_market_june_2 100%[===================>]  10.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-17 16:18:59 (112 MB/s) - ‘stock_market_june_2023.zip’ saved [10638/10638]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializes a DirectoryLoader to load text files from the specified directory.\n",
        "loader = DirectoryLoader('./stock_market_june_2023/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "# Loads all the documents present in the directory.\n",
        "documents = loader.load()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PTzuUMCehXbi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializes a RecursiveCharacterTextSplitter with a specified chunk size and overlap.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# Splits the loaded documents into chunks of text using the defined text_splitter.\n",
        "texts = text_splitter.split_documents(documents)\n"
      ],
      "metadata": {
        "id": "EM_p4a18ieve"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8pCeR4QihPg",
        "outputId": "65b284d7-952e-4b20-b501-c30de126e735"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAu4uVciijSd",
        "outputId": "98914421-ef9c-4e05-ac75-3ec0f6d3c0c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='The global shift towards electric vehicles (EVs) is driving an exponential increase in electricity demand. Countries worldwide, including oil-producing nations, are turning to nuclear energy to meet this growing need while transitioning away from fossil fuels. Consequently, the demand for uranium, essential for fueling the nuclear power sector, has experienced a significant surge in the past year after decades of stagnation, clearly showcased in the uranium spot price.', metadata={'source': 'stock_market_june_2023/Kiplin Metals Inc.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cvawJo32JRXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create the DB"
      ],
      "metadata": {
        "id": "M9JmPuaLKIsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets the directory where the embeddings will be stored.\n",
        "persist_directory = 'db'\n",
        "\n",
        "# Sets the OpenAI Embeddings object as the embedding to use.\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# Uses the Chroma module to convert the texts into embeddings using the  OpenAI Embeddings\n",
        "# The resulting embeddings are stored in the persist_directory.\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)\n"
      ],
      "metadata": {
        "id": "tGaaYEE-jAka"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Persists the generated embeddings database to disk.\n",
        "vectordb.persist()\n",
        "\n",
        "# Releases the memory held by the vectordb object by setting it to None.\n",
        "vectordb = None\n"
      ],
      "metadata": {
        "id": "R5LmOmdFjEEN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Re-initializes the Chroma object from the persisted directory with the specified embeddings.\n",
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n"
      ],
      "metadata": {
        "id": "_VORWEgEjGd8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a retriever"
      ],
      "metadata": {
        "id": "RHOH29VuKWr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializes a retriever object from the vectordb with a specified number of search results (k=3).\n",
        "# The vectordb.as_retriever() function is likely converting the Chroma object, which contains vectorized representations of text, into a retriever object.\n",
        "# The retriever can be used to find the most similar vectors in the database given a query vector.\n",
        "# The search_kwargs={\"k\": 3} argument suggests that the retriever will return the top 3 most similar vectors for each query.\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n"
      ],
      "metadata": {
        "id": "C-FXvoxgjI-G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a chain"
      ],
      "metadata": {
        "id": "QiFeFUmaKZi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializes a RetrievalQA object with the specified OpenAI(), retriever, and chain type.\n",
        "# The return_source_documents parameter set to True means the original source documents will be included in the returned results.\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)\n"
      ],
      "metadata": {
        "id": "WP9PVAUijeGV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # This function processes the response from a Language Model (llm) and prints the result and sources.\n",
        "def process_llm_response(llm_response):\n",
        "    # Prints the 'result' field from the response, which likely contains the answer from the language model.\n",
        "    print(llm_response['result'])\n",
        "\n",
        "    print('\\n\\nSources:')\n",
        "    # Iterates over the 'source_documents' field in the response, which contains the documents where the answer was found.\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        # Prints the 'source' metadata from each document.\n",
        "        print(source.metadata['source'])\n",
        "\n"
      ],
      "metadata": {
        "id": "tpblNhDUjjXG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Could you please enumerate the companies that have been highlighted for their potential stock growth\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW4r2sf3jrsM",
        "outputId": "c1b22ddc-879d-4c3b-92a0-84c017e6defb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The companies that have been highlighted for their potential stock growth are Arbor Metals Corp., Tesla Inc., Kiplin Metals Inc., Microsoft, NVIDIA, Shopify, Intuitive Surgical, and MercadoLibre.\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/stock_market.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how many companies that have been highlighted for their potential stock growth\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXpdDfkF2Nta",
        "outputId": "830777e9-dd24-4506-b0ca-3a265a7fdf55"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 8\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/stock_market.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the top five companies and how much did their stock value increase?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nz8Bk330sqD",
        "outputId": "b6c76aa6-2020-437a-bf86-1baaf863526f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Palantir soared by over 74%, Nvidia witnessed a growth of over 34%, Crowdstrike Holdings increased by over 30%, Shopify saw a rise of over 19%, and Our insights and articles about these stocks collectively yielded a remarkable 57% return last month for our readers who took action on our recommendations.\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/Arbor Metals Corp.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much has Microsoft invested in OpenAI?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i4xVyvE0_PW",
        "outputId": "4db5f451-1045-4ba8-f744-0122f9a5910f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Microsoft has invested $1 billion in OpenAI.\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/Microsoft Corporation.txt\n",
            "stock_market_june_2023/Microsoft Corporation.txt\n",
            "stock_market_june_2023/Microsoft Corporation.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What were the reasons behind Shopify's decision to lay off a portion of its workforce\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLs8WKCq0oEp",
        "outputId": "67475a59-8907-464e-fbe7-5fb66dfeea03"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " To reduce overhead costs and make Shopify more asset-light in the long run.\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/Shopify.txt\n",
            "stock_market_june_2023/Shopify.txt\n",
            "stock_market_june_2023/Shopify.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How does NVIDIA's dominance in the GPU market contribute to its strategic position in the AI industry?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv_AmNzQ09ec",
        "outputId": "511f9526-ff1c-42ef-ae1b-287948cc7810"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " NVIDIA's dominance in the GPU market allows them to provide hardware, like their A100 and H100 chips, to AI platforms like ChatGPT and Alphabet's A3 supercomputers. This reinforces confidence in NVIDIA's technological leadership and has helped drive their high share prices.\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/NVIDIA Corporation.txt\n",
            "stock_market_june_2023/NVIDIA Corporation.txt\n",
            "stock_market_june_2023/NVIDIA Corporation.txt\n"
          ]
        }
      ]
    }
  ]
}